{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from numbasom.core import lattice_closest_vectors\n",
    "from analysis.som import SOM\n",
    "from utils import save_output_to_pickle\n",
    "\n",
    "from models.olfaction.olfaction import Olfaction\n",
    "from models.vision.vision import Vision\n",
    "from models.audio.audio import Audio\n",
    "from models.touch.touch import Touch\n",
    "from models.memory.memory import Memory\n",
    "\n",
    "from config import Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in [0.01, 0.1, 0.2]:\n",
    "    args = Args()\n",
    "    args.setup_models = False # Set to True if first ever time running\n",
    "    args.experiment_name = \"main_results_lr_sweep\"\n",
    "    args.som_lr = lr\n",
    "\n",
    "    for modality in ([Olfaction(args), Vision(args), Audio(args), Touch(args), Memory(args)]):\n",
    "        print (\"\\n\", modality.modality, pd.Timestamp.now())\n",
    "        \n",
    "        # 1. Train/Download Model\n",
    "        modality.setup_model()\n",
    "        modality.setup_som()\n",
    "\n",
    "        # 2. Get activations for each patch\n",
    "        patches = modality.get_patches()\n",
    "        activation_list = []\n",
    "        for p in tqdm(patches):\n",
    "            p, static = modality.generate_static(p)\n",
    "            activation = modality.calculate_activations(static)\n",
    "            activation_list.append([p, activation])\n",
    "\n",
    "        # 3. Fit SOM\n",
    "        x_mat = torch.stack([x[1] for x in activation_list]).numpy()\n",
    "        som = modality.initialize_som(SOM)\n",
    "        lattice = som.train(x_mat, num_iterations=args.som_epochs, initialize=args.som_init, normalize=False, start_lrate=args.som_lr)\n",
    "        \n",
    "        # 4. Get coordinates for each BMU\n",
    "        coordinate_list = [x[0] for x in activation_list]\n",
    "        closest = lattice_closest_vectors(x_mat, lattice, additional_list=coordinate_list)\n",
    "\n",
    "        # 5. Save\n",
    "        output = {\"closest\": closest, \n",
    "                \"coord_map\": coordinate_list,\n",
    "                \"x_range\": (0, max([x[0][0] for x in activation_list])),\n",
    "                \"y_range\": (0, max([x[0][1] for x in activation_list])),\n",
    "                \"lattice\": lattice,\n",
    "                \"som\": None,\n",
    "                \"samples\": modality.sample_data,\n",
    "                \"modality\": modality.modality,\n",
    "                \"args\": args,\n",
    "                \"activations\": activation_list\n",
    "                }\n",
    "\n",
    "        save_output_to_pickle(output, args.experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cortical3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
